{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probabilities\n",
    "\n",
    "$P(A|B) = \\frac{P(A\\cap B)}{P(B)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = set([1,2,3]), set([1,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersection\n",
    "a & b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Union\n",
    "a | b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(a) + len(b)\n",
    "p_a_cap_b = len(a & b) / total # Cap means intersection.\n",
    "p_b = len(b) / total\n",
    "p_a_given_b = p_a_cap_b / p_b\n",
    "p_a_given_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Conditional Probabilities (Bayes Theorem)\n",
    "\n",
    "$P(B|A) = \\frac{P(A|B)P(B)}{P(A)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import io\n",
    "import re\n",
    "import email\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailObject:\n",
    "    def __init__(self, filepath, category=None):\n",
    "        self.filepath = filepath\n",
    "        self.category = category\n",
    "        self.mail = email.message_from_file(self.filepath)\n",
    "    \n",
    "    def subject(self):\n",
    "        return self.mail.get('Subject')\n",
    "\n",
    "    def body(self):\n",
    "        content_type = self.mail.get_content_type()\n",
    "        body = self.mail.get_payload(decode=True)\n",
    "        \n",
    "        if content_type == 'text/html':\n",
    "            return BeautifulSoup(body, 'html.parser').text\n",
    "        elif content_type == 'text/plain':\n",
    "            return body\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    NULL = u'\\u0000'\n",
    "    \n",
    "    @staticmethod\n",
    "    def tokenize(string):\n",
    "        return re.findall('\\w+', string.lower())\n",
    "    \n",
    "    @staticmethod\n",
    "    def ngram(string, ngram):\n",
    "        tokens = Tokenizer.tokenize(string)\n",
    "        \n",
    "        ngrams = []\n",
    "        \n",
    "        for i in range(len(tokens)):\n",
    "            shift = i - ngram + 1\n",
    "            padding = max(-shift, 0)\n",
    "            first_idx = max(shift, 0)\n",
    "            last_idx = first_idx + ngram - padding\n",
    "            \n",
    "            ngrams.append(Tokenizer.pad(tokens[first_idx:last_idx], padding))\n",
    "        \n",
    "        return ngrams\n",
    "\n",
    "    @staticmethod\n",
    "    def pad(tokens, padding):\n",
    "        padded_tokens = []\n",
    "        \n",
    "        for i in range(padding):\n",
    "            padded_tokens.append(Tokenizer.NULL)\n",
    "\n",
    "        return padded_tokens + tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamTrainer:\n",
    "    def __init__(self, training_files):\n",
    "        self.categories = set()\n",
    "    \n",
    "        for category, file in training_files:\n",
    "            self.categories.add(category)\n",
    "        \n",
    "        self.totals = defaultdict(float)\n",
    "        self.training = {c: defaultdict(float) \n",
    "                         for c in self.categories}\n",
    "        self.to_train = training_files\n",
    "    \n",
    "    def total_for(self, category):\n",
    "        return self.totals[category]\n",
    "    \n",
    "    def train(self):\n",
    "        for category, file in self.to_train:\n",
    "            email = EmailObject(io.open(file, 'r'))\n",
    "            \n",
    "            self.categories.add(category)\n",
    "            \n",
    "            for token in Tokenizer.unique_tokenizer(email.body()):\n",
    "                self.training[category][token] += 1\n",
    "                self.totals['_all'] += 1\n",
    "                self.totals[category] += 1\n",
    "        self.to_train = {}\n",
    "    \n",
    "    def score(self, email):\n",
    "        self.train()\n",
    "        cat_totals = self.totals\n",
    "        \n",
    "        aggregrates = {cat: cat_totals[c] / cat_totals['_all']\n",
    "                       for c in self.categories}\n",
    "        \n",
    "        for token in Tokenizer.unique_tokenizer(email.body()):\n",
    "            for cat in self.categories:\n",
    "                value = self.training[cat][token]\n",
    "                r = (value + 1)/(cat_totals[cat] + 1)\n",
    "                aggregates[cat] *= r\n",
    "\n",
    "        return aggregates\n",
    "    \n",
    "    def normalized_scores(self, email):\n",
    "        score = self.score(email)\n",
    "        scoresum = sum(score.values())\n",
    "        \n",
    "        normalized = {cat: (agg/scoresum)\n",
    "                      for cat, agg in score.items()}\n",
    "        \n",
    "        return normalized\n",
    "    \n",
    "    def preference(self):\n",
    "        return sorted(self.categories, key=lambda cat: self.total_for(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPlaintextEmailObject(unittest.TestCase):\n",
    "    CLRF = '\\n\\n'\n",
    "    \n",
    "    # The spelling is setUp.\n",
    "    def setUp(self):\n",
    "        self.plain_file = './data/plain.eml'\n",
    "        self.plaintext = io.open(self.plain_file, 'r')\n",
    "        self.text = self.plaintext.read()\n",
    "        self.plaintext.seek(0)\n",
    "        self.plain_email = EmailObject(self.plaintext)\n",
    "    \n",
    "    def test_parse_plain_body(self):\n",
    "        body = self.CLRF.join(self.text.split(self.CLRF)[1:])\n",
    "        # Decode the byte to utf-8.\n",
    "        self.assertEqual(str(self.plain_email.body(), 'utf-8'), body)\n",
    "    \n",
    "    def test_parses_the_subject(self):\n",
    "        subject = re.search('Subject: (.*)', self.text).group(1)\n",
    "        self.assertEqual(self.plain_email.subject(), subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestHTMLEmail(unittest.TestCase):\n",
    "    CLRF = '\\n\\n'\n",
    "    \n",
    "    def setUp(self):\n",
    "        self.html_file = io.open('./data/html.eml', 'r')\n",
    "        self.html = self.html_file.read()\n",
    "        self.html_file.seek(0)\n",
    "        self.html_email = EmailObject(self.html_file)\n",
    "    \n",
    "    def test_parses_stores_inner_text_html(self):\n",
    "        body = self.CLRF.join(self.html.split(self.CLRF)[1:])\n",
    "        expected = BeautifulSoup(body, 'html.parser').text\n",
    "        \n",
    "        # str.encode('utf-8')\n",
    "        self.assertEqual(self.html_email.body(), expected)\n",
    "        \n",
    "    def test_stores_subject(self):\n",
    "        subject = re.search('Subject: (.*)', self.html).group(1)\n",
    "        self.assertEqual(self.html_email.subject(), subject)\n",
    "        \n",
    "    class Classification:\n",
    "        def __init__(self, guess, score):\n",
    "            self.guess = guess\n",
    "            self.score = score\n",
    "            \n",
    "        def __eq__(self, other):\n",
    "            return self.guess == other.guess and self.score == other.score\n",
    "    \n",
    "        def classify(self, email):\n",
    "            score = self.score(email)\n",
    "            \n",
    "            max_score = 0.0\n",
    "            preference = self.preference()\n",
    "            max_key = preference[-1]\n",
    "            \n",
    "            for k, v in score.items():\n",
    "                if v > max_score:\n",
    "                    max_key = k\n",
    "                    max_score = v\n",
    "                elif v == max_score and preference.index(k) > preference.index(max_key):\n",
    "                    max_key = k\n",
    "                    max_score = v\n",
    "            return self.Classification(max_key, max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTokenizer(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.string = 'this is a test of the emergency broadcasting system'\n",
    "    \n",
    "    def test_downcasing(self):\n",
    "        expected = ['this', 'is', 'all', 'caps']\n",
    "        actual = Tokenizer.tokenize('THIS IS ALL CAPS')\n",
    "        self.assertEqual(expected, actual)\n",
    "    \n",
    "    def test_ngram(self):\n",
    "        expected = [\n",
    "            [u'\\u0000', 'quick'],\n",
    "            ['quick', 'brown'],\n",
    "            ['brown', 'fox']\n",
    "        ]\n",
    "        actual = Tokenizer.ngram('quick brown fox', 2)\n",
    "        self.assertEqual(expected, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSpamTrainer(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.training = [['spam', './data/plain.eml'],\n",
    "                         ['ham', './data/small.eml'],\n",
    "                         ['scram', './data/plain.eml']]\n",
    "        self.trainer = SpamTrainer(self.training)\n",
    "        file = io.open('./data/plain.eml', 'r')\n",
    "        self.email = EmailObject(file)\n",
    "    \n",
    "    def test_multiple_categories(self):\n",
    "        categories = self.trainer.categories\n",
    "        expected = set([k for k, v in self.training])\n",
    "        self.assertEqual(categories, expected)\n",
    "        \n",
    "    def test_counts_all_at_zero(self):\n",
    "        for cat in ['_all', 'spam', 'ham', 'scram']:\n",
    "            self.assertEqual(self.trainer.total_for(cat), 0)\n",
    "            \n",
    "    def test_probability_being_1_over_n(self):\n",
    "        trainer = self.trainer\n",
    "        scores = trainer.score(self.email).values()\n",
    "        \n",
    "        self.assertAlmostEqual(scores[0], scores[-1])\n",
    "        \n",
    "        for i in range(len(scores) - 1):\n",
    "            self.assertAlmostEqual(scores[i], scores[i+1])\n",
    "            \n",
    "    def test_adds_up_to_one(self):\n",
    "        trainer = self.trainer\n",
    "        scores = trainer.normalized_score(self.email).values()\n",
    "        self.assertAlmostEqual(sum(scores), 1)\n",
    "        self.assertAlmostEqual(scores[0], 1/2.0)\n",
    "        \n",
    "    def test_preference_category(self):\n",
    "        trainer = self.trainer\n",
    "        expected = sorted(trainer.categories, key=lambda cat: trainer.total_for(cat))\n",
    "        self.assertEqual(trainer.preference(), expected)\n",
    "        \n",
    "    def test_give_preference_to_whatever_has_the_most(self):\n",
    "        trainer = self.trainer\n",
    "        score = trainer.score(self.email)\n",
    "        \n",
    "        preference = trainer.preference()[-1]\n",
    "        preference_score = score[preference]\n",
    "        \n",
    "        expected = SpamTrainer.Classification(preference, preference_score)\n",
    "        self.assertEqual(trainer.classify(self.email), expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F./usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/unittest/suite.py:84: ResourceWarning: unclosed file <_io.TextIOWrapper name='./data/html.eml' mode='r' encoding='UTF-8'>\n",
      "  return self.run(*args, **kwds)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "./usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/unittest/suite.py:107: ResourceWarning: unclosed file <_io.TextIOWrapper name='./data/plain.eml' mode='r' encoding='UTF-8'>\n",
      "  for index, test in enumerate(self):\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "./usr/local/Cellar/python/3.7.3/Frameworks/Python.framework/Versions/3.7/lib/python3.7/unittest/suite.py:84: ResourceWarning: unclosed file <_io.TextIOWrapper name='./data/plain.eml' mode='r' encoding='UTF-8'>\n",
      "  return self.run(*args, **kwds)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "....\n",
      "======================================================================\n",
      "FAIL: test_parses_stores_inner_text_html (__main__.TestHTMLEmail)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-166-36814c579247>\", line 15, in test_parses_stores_inner_text_html\n",
      "    self.assertEqual(self.html_email.body(), expected)\n",
      "AssertionError: '\\n\\n[1370 chars] you.\\\\u2020 No teasing. No grand testimonies![2036 chars]\\n\\n' != '\\n\\n[1370 chars] you.â€  No teasing. No grand testimonies! No\\nk[2024 chars]\\n\\n'\n",
      "Diff is 3878 characters long. Set self.maxDiff to None to see it.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 8 tests in 0.119s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-argument-is-excluded'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%bash is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%%bash open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
