{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probabilities\n",
    "\n",
    "$P(A|B) = \\frac{P(A\\cap B)}{P(B)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = set([1,2,3]), set([1,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersection\n",
    "a & b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Union\n",
    "a | b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(a) + len(b)\n",
    "p_a_cap_b = len(a & b) / total # Cap means intersection.\n",
    "p_b = len(b) / total\n",
    "p_a_given_b = p_a_cap_b / p_b\n",
    "p_a_given_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Conditional Probabilities (Bayes Theorem)\n",
    "\n",
    "$P(B|A) = \\frac{P(A|B)P(B)}{P(A)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('text/plain',\n",
       " 'Wanna see sexually curious teens playing with each other?\\n\\nhttp://www.site-personals.com <-- click h')"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/plain.eml') as f:\n",
    "    msg = email.message_from_file(f)\n",
    "msg.get_content_type(), msg.get_payload(decode=False)[:100] # Decode=True will return bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('text/html',\n",
       " \"<body lang=EN-US>\\n\\n<div class=Section1>\\n\\n<p class=MsoBodyText style='text-align:justify'><b>CONSANTL\")"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/html.eml') as f:\n",
    "    msg = email.message_from_file(f)\n",
    "msg.get_content_type(), msg.get_payload(decode=False)[:100] # Decode=True will return bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One of a kind Money maker! Try it for free!'"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get the email subject.\n",
    "msg.get('Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nCONSANTLY being\\nbombarded by so-called ìFREEî money-making systems that teases you with limited\\nin'"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parsing HTML email.\n",
    "BeautifulSoup(msg.get_payload(decode=False), 'html.parser').text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import email\n",
    "import unittest\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailObject:\n",
    "    def __init__(self, file, category=None):\n",
    "        self.mail = email.message_from_file(file)\n",
    "        self.category = category\n",
    "\n",
    "    def subject(self):\n",
    "        \"\"\"Returns the email subject.\"\"\"\n",
    "        return self.mail.get('Subject')\n",
    "\n",
    "    def body(self):\n",
    "        \"\"\"Normalizes the content of the body to plain text if it is of type HTML.\"\"\"\n",
    "        content_type = self.mail.get_content_type()\n",
    "        body = self.mail.get_payload(decode=False)\n",
    "        \n",
    "        if content_type == 'text/html':\n",
    "            return BeautifulSoup(body, 'html.parser').text\n",
    "        elif content_type == 'text/plain':\n",
    "            return body\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    NULL = u'\\u0000'\n",
    "    \n",
    "    @staticmethod\n",
    "    def tokenize(string):\n",
    "        return re.findall('\\w+', string.lower())\n",
    "    \n",
    "    @staticmethod\n",
    "    def ngram(string, n=2):\n",
    "        s = string.split(' ')\n",
    "        result = []\n",
    "        for i in range(1, n + 1):\n",
    "            result.append([Tokenizer.NULL] * (n-i) + s)\n",
    "        return list(zip(*result))\n",
    "    \n",
    "    @staticmethod\n",
    "    def unique_tokenizer(string):\n",
    "        tokens = Tokenizer.tokenize(string)\n",
    "        return set(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamTrainer:\n",
    "    def __init__(self, training_files):\n",
    "        self.categories = set()\n",
    "    \n",
    "        for category, file in training_files:\n",
    "            self.categories.add(category)\n",
    "        \n",
    "        self.totals = defaultdict(float)\n",
    "        self.training = {c: defaultdict(float) \n",
    "                         for c in self.categories}\n",
    "        self.to_train = training_files\n",
    "    \n",
    "    def total_for(self, category):\n",
    "        return self.totals[category]\n",
    "    \n",
    "    def train(self):\n",
    "        for category, file in self.to_train:\n",
    "            # It's not utf-8.\n",
    "            with open(file, 'r', encoding='latin-1') as f:\n",
    "                email = EmailObject(f)\n",
    "            self.categories.add(category)\n",
    "            \n",
    "            for token in Tokenizer.unique_tokenizer(email.body()):\n",
    "                self.training[category][token] += 1\n",
    "                self.totals['_all'] += 1\n",
    "                self.totals[category] += 1\n",
    "        self.to_train = {}\n",
    "    \n",
    "    def score(self, email):\n",
    "        self.train()\n",
    "        cat_totals = self.totals\n",
    "        \n",
    "        aggregates = {c: cat_totals[c] / cat_totals['_all']\n",
    "                      for c in self.categories}\n",
    "        \n",
    "        for token in Tokenizer.unique_tokenizer(email.body()):\n",
    "            for cat in self.categories:\n",
    "                value = self.training[cat][token]\n",
    "                r = (value + 1)/(cat_totals[cat] + 1)\n",
    "                aggregates[cat] *= r\n",
    "\n",
    "        return aggregates\n",
    "    \n",
    "    def normalized_score(self, email):\n",
    "        score = self.score(email)\n",
    "        scoresum = sum(score.values())\n",
    "        \n",
    "        normalized = {cat: (agg/scoresum)\n",
    "                      for cat, agg in score.items()}\n",
    "        \n",
    "        return normalized\n",
    "    \n",
    "    def preference(self):\n",
    "        return sorted(self.categories, key=lambda cat: self.total_for(cat))\n",
    "    \n",
    "    class Classification:\n",
    "        def __init__(self, guess, score):\n",
    "            self.guess = guess\n",
    "            self.score = score\n",
    "            \n",
    "        def __eq__(self, other):\n",
    "            return self.guess == other.guess and self.score == other.score\n",
    "    \n",
    "    def classify(self, email):\n",
    "        score = self.score(email)\n",
    "\n",
    "        max_score = 0.0\n",
    "        preference = self.preference()\n",
    "        max_key = preference[-1]\n",
    "\n",
    "        for k, v in score.items():\n",
    "            if v > max_score:\n",
    "                max_key = k\n",
    "                max_score = v\n",
    "            elif v == max_score and preference.index(k) > preference.index(max_key):\n",
    "                max_key = k\n",
    "                max_score = v\n",
    "        return self.Classification(max_key, max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPlaintextEmailObject(unittest.TestCase):\n",
    "    CLRF = '\\n\\n'\n",
    "    \n",
    "    # The spelling is setUp.\n",
    "    def setUp(self):\n",
    "        self.plain_file = './data/plain.eml'\n",
    "        with open(self.plain_file, 'r') as f:\n",
    "            self.plaintext = f\n",
    "            self.text = f.read()\n",
    "            self.plaintext.seek(0)\n",
    "            self.plain_email = EmailObject(self.plaintext)\n",
    "            \n",
    "    def tearDown(self):\n",
    "        self.plaintext.close()\n",
    "    \n",
    "    def test_parse_plain_body(self):\n",
    "        body = self.CLRF.join(self.text.split(self.CLRF)[1:])\n",
    "        self.assertEqual(self.plain_email.body(), body)\n",
    "    \n",
    "    def test_parses_the_subject(self):\n",
    "        subject = re.search('Subject: (.*)', self.text).group(1)\n",
    "        self.assertEqual(self.plain_email.subject(), subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestHTMLEmail(unittest.TestCase):\n",
    "    CLRF = '\\n\\n'\n",
    "    \n",
    "    def setUp(self):\n",
    "        with open('./data/html.eml', 'r') as f:\n",
    "            self.html_file = f\n",
    "            self.html = self.html_file.read()\n",
    "            self.html_file.seek(0)\n",
    "            self.html_email = EmailObject(self.html_file)\n",
    "\n",
    "    def tearDown(self):\n",
    "        self.html_file.close()\n",
    "        \n",
    "    def test_parses_stores_inner_text_html(self):\n",
    "        body = self.CLRF.join(self.html.split(self.CLRF)[1:])\n",
    "        expected = BeautifulSoup(body, 'html.parser').text\n",
    " \n",
    "        self.assertEqual(self.html_email.body(), expected)\n",
    "        \n",
    "    def test_stores_subject(self):\n",
    "        subject = re.search('Subject: (.*)', self.html).group(1)\n",
    "        self.assertEqual(self.html_email.subject(), subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTokenizer(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.string = 'this is a test of the emergency broadcasting system'\n",
    "    \n",
    "    def test_downcasing(self):\n",
    "        expected = ['this', 'is', 'all', 'caps']\n",
    "        actual = Tokenizer.tokenize('THIS IS ALL CAPS')\n",
    "        self.assertEqual(expected, actual)\n",
    "    \n",
    "    def test_ngram(self):\n",
    "        expected = [\n",
    "            (u'\\u0000', 'quick'),\n",
    "            ('quick', 'brown'),\n",
    "            ('brown', 'fox')\n",
    "        ]\n",
    "        actual = Tokenizer.ngram('quick brown fox', 2)\n",
    "        self.assertEqual(expected, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSpamTrainer(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.training = [['spam', './data/plain.eml'],\n",
    "                         ['ham', './data/small.eml'],\n",
    "                         ['scram', './data/plain.eml']]\n",
    "        self.trainer = SpamTrainer(self.training)\n",
    "        with open('./data/plain.eml', 'r') as f:\n",
    "            self.file = f\n",
    "            self.email = EmailObject(self.file)\n",
    "            \n",
    "    def tearDown(self):\n",
    "        self.file.close()\n",
    "    \n",
    "    def test_multiple_categories(self):\n",
    "        categories = self.trainer.categories\n",
    "        expected = set([k for k, v in self.training])\n",
    "        self.assertEqual(categories, expected)\n",
    "        \n",
    "    def test_counts_all_at_zero(self):\n",
    "        for cat in ['_all', 'spam', 'ham', 'scram']:\n",
    "            self.assertEqual(self.trainer.total_for(cat), 0)\n",
    "            \n",
    "    def test_probability_being_1_over_n(self):\n",
    "        trainer = self.trainer\n",
    "        scores = list(trainer.score(self.email).values())\n",
    "        \n",
    "        self.assertAlmostEqual(scores[0], scores[-1])\n",
    "        \n",
    "        for i in range(len(scores) - 1):\n",
    "            self.assertAlmostEqual(scores[i], scores[i+1])\n",
    "            \n",
    "    def test_adds_up_to_one(self):\n",
    "        trainer = self.trainer\n",
    "        scores = list(trainer.normalized_score(self.email).values())\n",
    "        self.assertAlmostEqual(sum(scores), 1)\n",
    "        self.assertAlmostEqual(scores[0], 1/2.0)\n",
    "        \n",
    "    def test_preference_category(self):\n",
    "        trainer = self.trainer\n",
    "        expected = sorted(trainer.categories, key=lambda cat: trainer.total_for(cat))\n",
    "        self.assertEqual(trainer.preference(), expected)\n",
    "        \n",
    "    def test_give_preference_to_whatever_has_the_most(self):\n",
    "        trainer = self.trainer\n",
    "        score = trainer.score(self.email)\n",
    "        \n",
    "        preference = trainer.preference()[-1]\n",
    "        preference_score = score[preference]\n",
    "        \n",
    "        expected = SpamTrainer.Classification(preference, preference_score)\n",
    "        self.assertEqual(trainer.classify(self.email), expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "............\n",
      "----------------------------------------------------------------------\n",
      "Ran 12 tests in 0.048s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-argument-is-excluded'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%bash is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%%bash open ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_training_data(fold_file):\n",
    "    training_data = []\n",
    "    with open(fold_file, 'r') as f:\n",
    "        for line in f:\n",
    "            target, filepath = line.rstrip().split(' ')\n",
    "            # ./data/TRAINING/TRAIN_00002.eml\n",
    "            # Remap the path\n",
    "            filepath = filepath.replace('./data', './data/naive_bayes/data')\n",
    "            training_data.append([target, filepath])\n",
    "    print(training_data[0])\n",
    "    return SpamTrainer(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', './data/naive_bayes/data/TRAINING/TRAIN_00002.eml']\n"
     ]
    }
   ],
   "source": [
    "trainer = label_to_training_data('./data/naive_bayes/fixtures/fold1.label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_emails(keyfile):\n",
    "    emails = []\n",
    "    print(f'Parsing email for {keyfile}')\n",
    "    \n",
    "    with open(keyfile, 'r') as f:\n",
    "        for line in f:\n",
    "            label, file = line.rstrip().split(' ')\n",
    "            file = file.replace('./data', './data/naive_bayes/data')\n",
    "            with open(file, 'r', encoding='latin-1') as labelfile:\n",
    "                emails.append(EmailObject(labelfile, category=label))\n",
    "    print(f'Done parsing file for {keyfile}')\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing email for ./data/naive_bayes/fixtures/fold2.label\n",
      "Done parsing file for ./data/naive_bayes/fixtures/fold2.label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmailObject at 0x1180a2a58>"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = parse_emails('./data/naive_bayes/fixtures/fold2.label')\n",
    "emails[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%bash is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%%bash open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(trainer, set_of_emails):\n",
    "    correct = 0\n",
    "    false_positives = 0.0\n",
    "    false_negatives = 0.0\n",
    "    confidence = 0.0\n",
    "    \n",
    "    for email in set_of_emails:\n",
    "        classification = trainer.classify(email)\n",
    "        confidence += classification.score\n",
    "        \n",
    "        if classification.guess == 'spam' and email.category == 'ham':\n",
    "            false_positives += 1\n",
    "        elif classification.guess == 'ham' and email.category == 'spam':\n",
    "            false_negatives += 1\n",
    "        else:\n",
    "            correct += 1\n",
    "    \n",
    "    total = false_positives + false_negatives + correct\n",
    "    \n",
    "    false_positive_rate = false_positives / total\n",
    "    false_negative_rate = false_negatives / total\n",
    "    accuracy = (false_positives + false_negatives) / total\n",
    "    message = f\"\"\"\n",
    "        False Positives: {false_positive_rate}\n",
    "        False Negatives: {false_negative_rate}\n",
    "        Accuracy: {accuracy}\n",
    "    \"\"\"\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        False Positives: 0.0004623208506703652\n",
      "        False Negatives: 0.21128062875635692\n",
      "        Accuracy: 0.21174294960702728\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "validate(trainer, emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
